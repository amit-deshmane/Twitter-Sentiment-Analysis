learning_rate = 0.0001
num_iterations = 200

#Convolution input word embeddings
x1_size = 48000 # 120 * 400
x1_width = 120  # size of document in # tokens
x1_height = 400 # word embedding size
x1_channels = 1;

#Convolution input lexicons
x2_size = 360   # 120 * 3
x2_width = 120  # size of document in # tokens
x2_height = 3   # number of lexicons
x2_channels = 1;

#labels
l_size = 3
batch_size = 100

labels = ['positive', 'negative', 'objective']

#Convolution filters on 1- word embeddings, 2- lexicons
filter1_sizes = [1,2,3,4,5]
filter2_sizes = [3,4,5]

#Dropout
train_keep_prob = 0.7
test_keep_prob = 1.0

#RNN
num_hidden1 = 256


#Weight Initialization : Xavier
